# Quick Summer Summary ðŸ˜…

I read an article from Korean Journal of Radiology which had some nice things to say about multimodal models on radiology and health care.

The issues it mostly talks about were : 

* achieving generalizability of AI models

* establishing the explainability of the decision-making process

  

-> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10613849/

>To overcome these issues, some of the various possible solutions are as follows:
>
>inclusion of training with longitudinal and multimodal datasets, dense training with multitask and multimodal learning, new  generative models including anomaly detection, XAI
>
>--- From Summary and conclusion

---



I Mostly read on Collecting data and tokenization , since that will be our first steps.



For Data:

* Medpix2.0
  * 12,000 patient case scenarios,9,000 topics, and nearly 59,000 images.
  * But Far less than what 4m pretrains on which is 12M (CC12M).
  * But Medpix claims : `CLIP succeeds in achieving competitive performance in zero-shotcontexts on a wide range of classification datasets by learning the relationshipsbetween images and their textual descriptions `
  * 






For tokenization

*



Just so that its not complete replication of their work. I will make some changes by taking pieces of others architectures so that i could do ablation studies [Thats a research gap i think].

